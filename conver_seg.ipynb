{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rigid_co import *\n",
    "\n",
    "def co_registration_segmentation(dict_path='data_dict_bif_angl_pre_post.pt', seg_moving_path_folder='data/post_pci_prediction_LaW_merged304_all/', seg_target_path_folder='data/pre_pci_prediction_LaW_merged304_all/',save_segmentation_folder='data/registered_segmentation/'):\n",
    "\n",
    "    dict = torch.load(dict_path)\n",
    "    #for patient_id in dict.keys():\n",
    "    #patient_id = 'DK_AHU_00020'\n",
    "    if patient_id in dict.keys():\n",
    "        organized_pairs, ang_big = dict[patient_id]['bif_(pre_t_post_m)']\n",
    "\n",
    "        moving_path_mask=seg_moving_path_folder+patient_id+'.nii.gz'\n",
    "        target_path_mask=seg_target_path_folder+patient_id+'.nii.gz'\n",
    "\n",
    "        # load segmentation data\n",
    "        img = nib.load(target_path_mask)\n",
    "        img_data_pre = img.get_fdata() \n",
    "        img = nib.load(moving_path_mask)\n",
    "        img_data_post = img.get_fdata()\n",
    "\n",
    "\n",
    "        sdf_ct= distance_transform_edt(torch.tensor(img_data_post).permute(2, 0, 1))  \n",
    "        sdf_oct= distance_transform_edt(torch.tensor(img_data_pre).permute(2, 0, 1))\n",
    "\n",
    "        CT_sdf_cpr = torch.tensor(sdf_ct).unsqueeze(0)\n",
    "        OCT_sdf_cpr = torch.tensor(sdf_oct).unsqueeze(0)\n",
    "\n",
    "\n",
    "        CT_selected_indices = torch.tensor([t[0] for t in organized_pairs])\n",
    "        OCT_selected_indices = torch.tensor([t[1] for t in organized_pairs])\n",
    "        idx_OCT_shift = OCT_selected_indices[0]\n",
    "        idx_CT_shift = CT_selected_indices[0]\n",
    "\n",
    "        # indices following shift based on first bifurcation\n",
    "        OCT_selected_indices_shift = OCT_selected_indices - idx_OCT_shift\n",
    "        print('OCT_selected_indices_shift:must start with 0', OCT_selected_indices_shift)\n",
    "        CT_selected_indices_shift = CT_selected_indices - idx_CT_shift\n",
    "        print('CT_selected_indices_shift:must start with 0', CT_selected_indices_shift)\n",
    "        CT_sdf_cpr = CT_sdf_cpr[:,CT_selected_indices[0]:,...]\n",
    "        OCT_sdf_cpr = OCT_sdf_cpr[:,OCT_selected_indices[0]:,...]\n",
    "\n",
    "        # cat same length\n",
    "        if CT_sdf_cpr.shape[1] < OCT_sdf_cpr.shape[1]:\n",
    "            OCT_sdf_cpr = OCT_sdf_cpr[:, :CT_sdf_cpr.shape[1], ...]\n",
    "        else:\n",
    "            CT_sdf_cpr = CT_sdf_cpr[:, :OCT_sdf_cpr.shape[1], ...]\n",
    "        #angl of bifurcation\n",
    "        #RULES\n",
    "        # 1. Moving image is CT refernce to target OCT\n",
    "        # 2. Clockwise is negative, counter clockwise is positive\n",
    "        # 3. Maintain the same SIGN orientation of the moving image for ALL bifurcations (ALL positive or ALL negative)\n",
    "        # 4. Maximum angle is 180 degrees or 3.14 radians\n",
    "        print('ang_for each bifurcation:',ang_big)\n",
    "        angl  = ang_big\n",
    "        theta_shift = angl\n",
    "\n",
    "\n",
    "        t = torch.linspace(0, 1,CT_sdf_cpr.shape[1])\n",
    "        vector = torch.full((CT_sdf_cpr.shape[1],1), float('nan'))\n",
    "\n",
    "        for i,b in zip(CT_selected_indices_shift,torch.tensor(theta_shift)):\n",
    "            vector[i] = b\n",
    "        # parametrized spline\n",
    "        coeffs = natural_cubic_spline_coeffs(t, vector)\n",
    "        splines = NaturalCubicSpline(coeffs)\n",
    "        theta_vec_cubic = splines.evaluate(t)\n",
    "        mask = ~np.isnan(vector.numpy()).flatten()\n",
    "        t_clean = t.numpy()[mask]\n",
    "        vector_clean = vector.numpy()[mask].flatten()\n",
    "        pchip = PchipInterpolator(t_clean, vector_clean)\n",
    "        # add end point by cubic spline\n",
    "        arr = pchip(t)  # Get the array\n",
    "        arr[CT_selected_indices_shift[-1]:] = theta_vec_cubic[CT_selected_indices_shift[-1]:].reshape(-1)  # Modify the slice  \n",
    "        ct_data_or  = torch.tensor(img_data_post[:,:,idx_CT_shift:CT_sdf_cpr.shape[1]+idx_CT_shift]).permute(2, 0, 1).unsqueeze(0)\n",
    "        oct_data_or = torch.tensor(img_data_pre[:,:,idx_OCT_shift:OCT_sdf_cpr.shape[1]+idx_OCT_shift]).permute(2, 0, 1).unsqueeze(0)\n",
    "        ph = ridgit_register(CT_sdf_cpr[0], torch.tensor(np.array(arr).reshape(-1,1)))\n",
    "        ph_or = ridgit_register(ct_data_or[0], torch.tensor(np.array(arr).reshape(-1,1)))\n",
    "        ct_circl = []\n",
    "        for i in range(CT_sdf_cpr.shape[1]):\n",
    "            orientation,centroid = center_circle(ph.unsqueeze(0)[0,i,...].detach().numpy()>0)\n",
    "            ct_circl.append(centroid)\n",
    "\n",
    "        oct_circl= []\n",
    "        for i in range(OCT_sdf_cpr.shape[1]):\n",
    "            orientation,centroid = center_circle(OCT_sdf_cpr[0,i,...].detach().numpy()>0)\n",
    "            oct_circl.append(centroid)\n",
    "\n",
    "        # Convert centers to numpy arrays for easier processing\n",
    "        oct_circl = np.array([c for c in oct_circl if c[0] is not None and c[1] is not None])\n",
    "        ct_circl = np.array([c for c in ct_circl if c[0] is not None and c[1] is not None])\n",
    "    \n",
    "        # Ensure there are enough points to apply the filter\n",
    "        if len(oct_circl) > 31 and len(ct_circl) > 31:\n",
    "            # Smooth the center coordinates\n",
    "            oct_circl = np.copy(oct_circl)\n",
    "            ct_circl = np.copy(ct_circl)\n",
    "            \n",
    "            for dim in range(2):  # For both x and y dimensions\n",
    "                oct_circl[:, dim] = savgol_filter(oct_circl[:, dim], 32, 2)\n",
    "                oct_circl[:, dim] = savgol_filter(ct_circl[:, dim], 32, 2)\n",
    "    \n",
    "        #ph_or_smooth_min = rotation(ph_or.unsqueeze(0),OCT_centers_smoothedmin,CT_centers_smoothedmin)\n",
    "        #ph_translation_smooth_min = rotation(ph.unsqueeze(0),OCT_centers_smoothedmin,CT_centers_smoothedmin)\n",
    "        #ph_circle = rotation(ph.unsqueeze(0),oct_circl,ct_circl)\n",
    "        ph_or_circle = rotation(ph_or.unsqueeze(0),oct_circl,ct_circl)\n",
    "\n",
    "\n",
    "        patient = patient_id\n",
    "        #d = torch.load('data_dict_bif_angl.pt')\n",
    "        d = {}\n",
    "        d[patient] = {}\n",
    "        ############################ PRE-FINAL ############################\n",
    "\n",
    "        d[patient]['bif_(PostTarget_StentMoving)'] = [organized_pairs,ang_big]\n",
    "        d[patient]['bif_(PostTarget_StentMoving)'][0]\n",
    "        # substract first tuple from all tuples in the list\n",
    "        l = [(x[0]-d[patient]['bif_(PostTarget_StentMoving)'][0][0][0], x[1]-d[patient]['bif_(PostTarget_StentMoving)'][0][0][1]) for x in d[patient]['bif_(PostTarget_StentMoving)'][0]]\n",
    "        fixed_image = oct_data_or.detach().numpy().squeeze().transpose(1, 2, 0)\n",
    "        moving_image = np.array(ph_or_circle).transpose(1, 2, 0)\n",
    "\n",
    "        bil = []\n",
    "        for i in range(len(l)-1):\n",
    "            \n",
    "            lengthf = fixed_image[:,:,l[i][1]:(l[i+1][1])].shape[-1]\n",
    "            lengthm = moving_image[:,:,l[i][0]:(l[i+1][0])].shape[-1]\n",
    "\n",
    "            frames = moving_image[:,:,l[i][0]:(l[i+1][0])]\n",
    "            print(lengthf-lengthm)\n",
    "            if (lengthf-lengthm)>0 and (l[i+1][1]-l[i][1])>5:\n",
    "                print('duplicate')\n",
    "                num_duplicates = lengthf - lengthm \n",
    "                sq = duplicate_frames(frames, num_duplicates=num_duplicates, exclusion_fraction=0.2)\n",
    "                bil.append(sq)\n",
    "            if (lengthf-lengthm)<0 and (l[i+1][1]-l[i][1])>5:\n",
    "                print('remove')\n",
    "                num_removals = lengthm - lengthf \n",
    "                sq = remove_frames(frames, num_removals=num_removals, exclusion_fraction=0.2)\n",
    "                bil.append(sq)\n",
    "\n",
    "            if (lengthf-lengthm)==0 or (l[i+1][1]-l[i][1])<=5:\n",
    "                print('normal')\n",
    "                bil.append(frames)\n",
    "        bil.append(moving_image[:,:,l[-1][0]:])\n",
    "        br = np.concatenate((bil),axis=2)\n",
    "        \n",
    "\n",
    "\n",
    "        brs = nib.Nifti1Image(br, np.eye(4))\n",
    "        nib.save(brs, save_segmentation_folder + patient+'post_seg.nii.gz')\n",
    "\n",
    "        fixed_images = nib.Nifti1Image(fixed_image[:,:,:br.shape[-1]], np.eye(4))       \n",
    "        nib.save(fixed_images, save_segmentation_folder + patient+'pre_seg.nii.gz')\n",
    "    #return fixed_image, br\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,b = co_registration_segmentation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load segmentation data\n",
    "img = nib.load('DK_AHU_00020pre.nii.gz')\n",
    "img_data_pre = img.get_fdata() \n",
    "img = nib.load('DK_AHU_00020post.nii.gz')\n",
    "img_data_post = img.get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(i):\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(15, 5))\n",
    "    \n",
    "    axs[0].imshow(f[...,i])\n",
    "    axs[0].set_title('Target(Pre)')\n",
    "    axs[1].imshow(img_data_pre[...,i])\n",
    "    axs[2].imshow(b[:,:,i])\n",
    "    axs[2].set_title('Resample random removel\\duplicate')\n",
    "    axs[3].imshow(img_data_post[...,i])\n",
    "    plt.show()\n",
    "\n",
    "# Interactive slider\n",
    "frame_slider = IntSlider(min=0, max=f.shape[1]-1, step=1, value=0)\n",
    "interact(show_images, i=frame_slider)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nameofmyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
