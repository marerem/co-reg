{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seg_rigid_co import *\n",
    "\n",
    "def co_registration_segmentation(dict_path='data_dict_bif_angl_pre_post.pt', seg_moving_path_folder='data/post_pci_prediction_LaW_merged304_all/', seg_target_path_folder='data/pre_pci_prediction_LaW_merged304_all/',save_segmentation_folder='data/registered_segmentation/'):\n",
    "\n",
    "    dict = torch.load(dict_path)\n",
    "    #for patient_id in dict.keys():\n",
    "    patient_id = 'DK_AHU_00020'\n",
    "    #for patient_id in patient_isd:\n",
    "    organized_pairs, ang_big = dict[patient_id]['bif_(pre_t_post_m)']\n",
    "\n",
    "    moving_path_mask=seg_moving_path_folder+patient_id+'.nii.gz'\n",
    "    target_path_mask=seg_target_path_folder+patient_id+'.nii.gz'\n",
    "\n",
    "    # load segmentation data\n",
    "    img = nib.load(target_path_mask)\n",
    "    img_data_pre = img.get_fdata() \n",
    "    img = nib.load(moving_path_mask)\n",
    "    img_data_post = img.get_fdata()\n",
    "\n",
    "\n",
    "    sdf_ct= distance_transform_edt(torch.tensor(img_data_post).permute(2, 0, 1))  \n",
    "    sdf_oct= distance_transform_edt(torch.tensor(img_data_pre).permute(2, 0, 1))\n",
    "\n",
    "    CT_sdf_cpr = torch.tensor(sdf_ct).unsqueeze(0)\n",
    "    OCT_sdf_cpr = torch.tensor(sdf_oct).unsqueeze(0)\n",
    "\n",
    "\n",
    "    CT_selected_indices = torch.tensor([t[0] for t in organized_pairs])\n",
    "    OCT_selected_indices = torch.tensor([t[1] for t in organized_pairs])\n",
    "    idx_OCT_shift = OCT_selected_indices[0]\n",
    "    idx_CT_shift = CT_selected_indices[0]\n",
    "\n",
    "    # indices following shift based on first bifurcation\n",
    "    OCT_selected_indices_shift = OCT_selected_indices - idx_OCT_shift\n",
    "    print('OCT_selected_indices_shift:must start with 0', OCT_selected_indices_shift)\n",
    "    CT_selected_indices_shift = CT_selected_indices - idx_CT_shift\n",
    "    print('CT_selected_indices_shift:must start with 0', CT_selected_indices_shift)\n",
    "    CT_sdf_cpr = CT_sdf_cpr[:,CT_selected_indices[0]:,...]\n",
    "    OCT_sdf_cpr = OCT_sdf_cpr[:,OCT_selected_indices[0]:,...]\n",
    "\n",
    "    # cat same length\n",
    "    if CT_sdf_cpr.shape[1] < OCT_sdf_cpr.shape[1]:\n",
    "        OCT_sdf_cpr = OCT_sdf_cpr[:, :CT_sdf_cpr.shape[1], ...]\n",
    "    else:\n",
    "        CT_sdf_cpr = CT_sdf_cpr[:, :OCT_sdf_cpr.shape[1], ...]\n",
    "    #angl of bifurcation\n",
    "    #RULES\n",
    "    # 1. Moving image is CT refernce to target OCT\n",
    "    # 2. Clockwise is negative, counter clockwise is positive\n",
    "    # 3. Maintain the same SIGN orientation of the moving image for ALL bifurcations (ALL positive or ALL negative)\n",
    "    # 4. Maximum angle is 180 degrees or 3.14 radians\n",
    "    print('ang_for each bifurcation:',ang_big)\n",
    "    angl  = ang_big\n",
    "    theta_shift = angl\n",
    "\n",
    "\n",
    "    t = torch.linspace(0, 1,CT_sdf_cpr.shape[1])\n",
    "    vector = torch.full((CT_sdf_cpr.shape[1],1), float('nan'))\n",
    "\n",
    "    for i,b in zip(CT_selected_indices_shift,torch.tensor(theta_shift)):\n",
    "        vector[i] = b\n",
    "    # parametrized spline\n",
    "    coeffs = natural_cubic_spline_coeffs(t, vector)\n",
    "    splines = NaturalCubicSpline(coeffs)\n",
    "    theta_vec_cubic = splines.evaluate(t)\n",
    "    mask = ~np.isnan(vector.numpy()).flatten()\n",
    "    t_clean = t.numpy()[mask]\n",
    "    vector_clean = vector.numpy()[mask].flatten()\n",
    "    pchip = PchipInterpolator(t_clean, vector_clean)\n",
    "    # add end point by cubic spline\n",
    "    arr = pchip(t)  # Get the array\n",
    "    arr[CT_selected_indices_shift[-1]:] = theta_vec_cubic[CT_selected_indices_shift[-1]:].reshape(-1)  # Modify the slice  \n",
    "    ct_data_or  = torch.tensor(img_data_post[:,:,idx_CT_shift:CT_sdf_cpr.shape[1]+idx_CT_shift]).permute(2, 0, 1).unsqueeze(0)\n",
    "    oct_data_or = torch.tensor(img_data_pre[:,:,idx_OCT_shift:OCT_sdf_cpr.shape[1]+idx_OCT_shift]).permute(2, 0, 1).unsqueeze(0)\n",
    "    ph = ridgit_register(CT_sdf_cpr[0], torch.tensor(np.array(arr).reshape(-1,1)))\n",
    "    ph_or = ridgit_register(ct_data_or[0], torch.tensor(np.array(arr).reshape(-1,1)))\n",
    "    ct_circl = []\n",
    "    for i in range(CT_sdf_cpr.shape[1]):\n",
    "        orientation,centroid = center_circle(ph.unsqueeze(0)[0,i,...].detach().numpy()>0)\n",
    "        ct_circl.append(centroid)\n",
    "\n",
    "    oct_circl= []\n",
    "    for i in range(OCT_sdf_cpr.shape[1]):\n",
    "        orientation,centroid = center_circle(OCT_sdf_cpr[0,i,...].detach().numpy()>0)\n",
    "        oct_circl.append(centroid)\n",
    "\n",
    "    # Convert centers to numpy arrays for easier processing\n",
    "    oct_circl = np.array([c for c in oct_circl if c[0] is not None and c[1] is not None])\n",
    "    ct_circl = np.array([c for c in ct_circl if c[0] is not None and c[1] is not None])\n",
    "\n",
    "    # Ensure there are enough points to apply the filter\n",
    "    if len(oct_circl) > 31 and len(ct_circl) > 31:\n",
    "        # Smooth the center coordinates\n",
    "        oct_circl = np.copy(oct_circl)\n",
    "        ct_circl = np.copy(ct_circl)\n",
    "        \n",
    "        for dim in range(2):  # For both x and y dimensions\n",
    "            oct_circl[:, dim] = savgol_filter(oct_circl[:, dim], 32, 2)\n",
    "            oct_circl[:, dim] = savgol_filter(ct_circl[:, dim], 32, 2)\n",
    "\n",
    "    #ph_or_smooth_min = rotation(ph_or.unsqueeze(0),OCT_centers_smoothedmin,CT_centers_smoothedmin)\n",
    "    #ph_translation_smooth_min = rotation(ph.unsqueeze(0),OCT_centers_smoothedmin,CT_centers_smoothedmin)\n",
    "    #ph_circle = rotation(ph.unsqueeze(0),oct_circl,ct_circl)\n",
    "    ph_or_circle = rotation(ph_or.unsqueeze(0),oct_circl,ct_circl)\n",
    "\n",
    "\n",
    "    patient = patient_id\n",
    "    #d = torch.load('data_dict_bif_angl.pt')\n",
    "    d = {}\n",
    "    d[patient] = {}\n",
    "\n",
    "\n",
    "    d[patient]['bif_(PostTarget_StentMoving)'] = [organized_pairs,ang_big]\n",
    "    d[patient]['bif_(PostTarget_StentMoving)'][0]\n",
    "    # substract first tuple from all tuples in the list\n",
    "    l = [(x[0]-d[patient]['bif_(PostTarget_StentMoving)'][0][0][0], x[1]-d[patient]['bif_(PostTarget_StentMoving)'][0][0][1]) for x in d[patient]['bif_(PostTarget_StentMoving)'][0]]\n",
    "    fixed_image = oct_data_or.detach().numpy().squeeze().transpose(1, 2, 0)\n",
    "    moving_image = np.array(ph_or_circle).transpose(1, 2, 0)\n",
    "\n",
    "    bil = []\n",
    "    for i in range(len(l)-1):\n",
    "        \n",
    "        lengthf = fixed_image[:,:,l[i][1]:(l[i+1][1])].shape[-1]\n",
    "        lengthm = moving_image[:,:,l[i][0]:(l[i+1][0])].shape[-1]\n",
    "\n",
    "        frames = moving_image[:,:,l[i][0]:(l[i+1][0])]\n",
    "        print(lengthf-lengthm)\n",
    "        if (lengthf-lengthm)>0 and (l[i+1][1]-l[i][1])>5:\n",
    "            print('duplicate')\n",
    "            num_duplicates = lengthf - lengthm \n",
    "            sq = duplicate_frames(frames, num_duplicates=num_duplicates, exclusion_fraction=0.2)\n",
    "            bil.append(sq)\n",
    "        if (lengthf-lengthm)<0 and (l[i+1][1]-l[i][1])>5:\n",
    "            print('remove')\n",
    "            num_removals = lengthm - lengthf \n",
    "            sq = remove_frames(frames, num_removals=num_removals, exclusion_fraction=0.2)\n",
    "            bil.append(sq)\n",
    "\n",
    "        if (lengthf-lengthm)==0 or (l[i+1][1]-l[i][1])<=5:\n",
    "            print('normal')\n",
    "            bil.append(frames)\n",
    "    bil.append(moving_image[:,:,l[-1][0]:])\n",
    "    br = np.concatenate((bil),axis=2)\n",
    "    \n",
    "\n",
    "\n",
    "    brs = nib.Nifti1Image(br, np.eye(4))\n",
    "    nib.save(brs, save_segmentation_folder + patient+'post_seg.nii.gz')\n",
    "\n",
    "    fixed_images = nib.Nifti1Image(fixed_image[:,:,:br.shape[-1]], np.eye(4))       \n",
    "    nib.save(fixed_images, save_segmentation_folder + patient+'pre_seg.nii.gz')\n",
    "    return fixed_image, br\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,b = co_registration_segmentation(dict_path='data_dict_bif_angl_pre_post.pt', \n",
    "                                seg_moving_path_folder=r'Z:\\shared\\Computational_Group\\Naravich\\P3_MIT\\post_pci_prediction_LaW_merged304_all\\\\',\n",
    "                                seg_target_path_folder=r'Z:\\shared\\Computational_Group\\Naravich\\P3_MIT\\pre_pci_prediction_LaW_merged304_all\\\\',\n",
    "                                save_segmentation_folder=r'data/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#impor nib\n",
    "import nibabel as nib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load segmentation data\n",
    "img = nib.load('data/DK_AHU_00020pre_seg.nii.gz')\n",
    "img_data_pre = img.get_fdata() \n",
    "img = nib.load('data/DK_AHU_00020post_seg.nii.gz')\n",
    "img_data_post = img.get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nib.load('Z:\\shared\\Computational_Group\\Mariia\\P3_MIT\\co-reg_pre_post_pci\\DK_AHU_00020pre.nii.gz')\n",
    "\n",
    "f = img.get_fdata()\n",
    "img = nib.load('Z:\\shared\\Computational_Group\\Mariia\\P3_MIT\\co-reg_pre_post_pci\\DK_AHU_00020post.nii.gz')\n",
    "b = img.get_fdata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import interact \n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, IntSlider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install --upgrade joblib loky\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(i):\n",
    "    fig, axs = plt.subplots(1, 4, figsize=(15, 5))\n",
    "    \n",
    "    axs[0].imshow(f[...,i])\n",
    "    axs[0].set_title('Target(Pre)')\n",
    "    axs[1].imshow(img_data_pre[...,i])\n",
    "    axs[2].imshow(b[:,:,i])\n",
    "    axs[2].set_title('Resample random removel\\duplicate')\n",
    "    axs[3].imshow(img_data_post[...,i])\n",
    "    plt.show()\n",
    "\n",
    "# Interactive slider\n",
    "frame_slider = IntSlider(min=0, max=f.shape[1]-1, step=1, value=0)\n",
    "interact(show_images, i=frame_slider)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "dict = torch.load('data_dict_bif_angl_pre_post.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['AU_MON_00001', 'AU_MON_00003', 'AU_MON_00004', 'AU_MON_00005', 'AU_MON_00007', 'AU_MON_00013', 'AU_MON_00017', 'BE_OLV_00008', 'BE_OLV_00010', 'BE_OLV_00014', 'BE_OLV_00018', 'BE_OLV_00020', 'BE_OLV_00021', 'BE_OLV_00024', 'BE_OLV_00028', 'BE_OLV_00029', 'BE_OLV_00031', 'BE_OLV_00033', 'BE_OLV_00034', 'BE_OLV_00039', 'BE_OLV_00041', 'BE_OLV_00043', 'BE_OLV_00045', 'BE_OLV_00050', 'BE_OLV_00053', 'BE_OLV_00058', 'DK_AHU_00002', 'DK_AHU_00007', 'DK_AHU_00010', 'DK_AHU_00011', 'DK_AHU_00013', 'DK_AHU_00015', 'DK_AHU_00018', 'DK_AHU_00019', 'DK_AHU_00021', 'DK_AHU_00022', 'DK_AHU_00024', 'DK_AHU_00025', 'DK_AHU_00027', 'DK_AHU_00029', 'JP_KOB_00003', 'JP_KOB_00004', 'JP_KOB_00008', 'JP_KOB_00009', 'JP_KOB_00010', 'KR_SNC_00006', 'KR_SNC_00008', 'DK_AHU_00008', 'DK_AHU_00009', 'DK_AHU_00020', 'DK_AHU_00026'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nameofmyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
