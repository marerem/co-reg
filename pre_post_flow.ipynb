{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rigid_co import *\n",
    "\n",
    "def co_registration(patient_id=None):\n",
    "\n",
    "    moving_path_mask='data/post_pci_prediction_LaW_merged304_all/'+patient_id+'.nii.gz'\n",
    "    target_path_mask='data/pre_pci_prediction_LaW_merged304_all/'+patient_id+'.nii.gz'\n",
    "    moving_path_raw='data/post/'+patient_id+'.nii.gz'\n",
    "    target_path_raw='data/pre/'+patient_id+'.nii.gz'\n",
    "\n",
    "    # load segmentation data\n",
    "    img = nib.load(target_path_mask)\n",
    "    img_data_pre = img.get_fdata() \n",
    "    img = nib.load(moving_path_mask)\n",
    "    img_data_post = img.get_fdata()\n",
    "\n",
    "    # load original data \n",
    "    pre_data = nib.load(target_path_raw).get_fdata()\n",
    "    post_data = nib.load(moving_path_raw).get_fdata()\n",
    "\n",
    "    sdf_ct= distance_transform_edt(torch.tensor(img_data_post).permute(2, 0, 1))  \n",
    "    sdf_oct= distance_transform_edt(torch.tensor(img_data_pre).permute(2, 0, 1))\n",
    "\n",
    "    CT_sdf_cpr = torch.tensor(sdf_ct).unsqueeze(0)\n",
    "    OCT_sdf_cpr = torch.tensor(sdf_oct).unsqueeze(0)\n",
    "    \"\"\"\n",
    "    # Plot areas\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \"\"\"\n",
    "    Area_CT_ori = torch.sum((CT_sdf_cpr > 0), dim=(0, 2, 3))\n",
    "    Area_OCT = torch.sum((OCT_sdf_cpr > 0), dim=(0, 2, 3))\n",
    "  \n",
    "    # detect bifurcation\n",
    "\n",
    "    root = tk.Tk()\n",
    "    root.title(\"Peaks Matcher GUI\")\n",
    "    app = PeaksMatcherGUI(master=root, Area_CT=Area_CT_ori, Area_OCT=Area_OCT, CT_image=CT_sdf_cpr>0, OCT_image=OCT_sdf_cpr>0,or_ct=torch.tensor(post_data).permute(2, 0, 1).unsqueeze(0),or_oct=torch.tensor(pre_data).permute(2, 0, 1).unsqueeze(0))\n",
    "    app.mainloop()\n",
    "    # Capture organized pairs before closing\n",
    "    #organized_pairs = organize_matched_pairs(app.highlighted_points)\n",
    "    organized_pairs,ang_big,an = organize_matched_pairss(app.saving_orientation,app.saving_orientation_angl_show)\n",
    "    print(\"Last organized pairs:\", organized_pairs)\n",
    "\n",
    "    left_count = sum(1 for item in an if item[1] == 'left')\n",
    "    right_count = sum(1 for item in an if item[1] == 'right')\n",
    "    an = np.array(an)\n",
    "    \n",
    "    if left_count>=right_count:\n",
    "        print(\"The orientation is left\")\n",
    "        print(left_count)\n",
    "        z = [float(x[0])* math.pi/180 for x in an] \n",
    "        z = [-abs(value) for value in z]\n",
    "        right_indices = [i for i, item in enumerate(an) if item[1] == 'right']\n",
    "        for i in right_indices:\n",
    "            z[i] = -6.28-z[i]\n",
    "    else:\n",
    "        print(right_count)\n",
    "        z = [float(x[0])* math.pi/180 for x in an]\n",
    "        left_indices = [i for i, item in enumerate(an) if item[1] == 'left'] \n",
    "        for i in left_indices:\n",
    "            z[i] = 6.28-z[i]\n",
    "  \n",
    "    #z = [float(x[0])* math.pi/180 for x in an]\n",
    "    #left_indices = [i for i, item in enumerate(an) if item[1] == 'left'] \n",
    "    #for i in left_indices:\n",
    "    #    z[i] = -z[i]\n",
    "   \n",
    "    ang_big = z\n",
    "\n",
    "    #organized_pairs,ang_big = [(85, 20), (202, 145), (252, 184), (267, 201), (278, 213), (300, 237), (311, 255)],[-1.6614562139956417, -1.78384488611824, -0.9853790354839929, -1.0967528289484558, -0.9783753580174395, -1.316573067865519, -1.086098709835318]\n",
    "    print(\"Anglel\",ang_big)\n",
    "    \n",
    " \n",
    "\n",
    "    CT_selected_indices = torch.tensor([t[0] for t in organized_pairs])\n",
    "    OCT_selected_indices = torch.tensor([t[1] for t in organized_pairs])\n",
    "    idx_OCT_shift = OCT_selected_indices[0]\n",
    "    idx_CT_shift = CT_selected_indices[0]\n",
    "\n",
    "    # indices following shift based on first bifurcation\n",
    "    OCT_selected_indices_shift = OCT_selected_indices - idx_OCT_shift\n",
    "    print('OCT_selected_indices_shift:must start with 0', OCT_selected_indices_shift)\n",
    "    CT_selected_indices_shift = CT_selected_indices - idx_CT_shift\n",
    "    print('CT_selected_indices_shift:must start with 0', CT_selected_indices_shift)\n",
    "    CT_sdf_cpr = CT_sdf_cpr[:,CT_selected_indices[0]:,...]\n",
    "    OCT_sdf_cpr = OCT_sdf_cpr[:,OCT_selected_indices[0]:,...]\n",
    "\n",
    "    # cat same length\n",
    "    if CT_sdf_cpr.shape[1] < OCT_sdf_cpr.shape[1]:\n",
    "        OCT_sdf_cpr = OCT_sdf_cpr[:, :CT_sdf_cpr.shape[1], ...]\n",
    "    else:\n",
    "        CT_sdf_cpr = CT_sdf_cpr[:, :OCT_sdf_cpr.shape[1], ...]\n",
    "    #angl of bifurcation\n",
    "    #RULES\n",
    "    # 1. Moving image is CT refernce to target OCT\n",
    "    # 2. Clockwise is negative, counter clockwise is positive\n",
    "    # 3. Maintain the same SIGN orientation of the moving image for ALL bifurcations (ALL positive or ALL negative)\n",
    "    # 4. Maximum angle is 180 degrees or 3.14 radians\n",
    "    print('ang_for each bifurcation:',ang_big)\n",
    "    angl  = ang_big\n",
    "    theta_shift = angl\n",
    "\n",
    "\n",
    "    t = torch.linspace(0, 1,CT_sdf_cpr.shape[1])\n",
    "    vector = torch.full((CT_sdf_cpr.shape[1],1), float('nan'))\n",
    "\n",
    "    for i,b in zip(CT_selected_indices_shift,torch.tensor(theta_shift)):\n",
    "        vector[i] = b\n",
    "    # parametrized spline\n",
    "    coeffs = natural_cubic_spline_coeffs(t, vector)\n",
    "    splines = NaturalCubicSpline(coeffs)\n",
    "    theta_vec_cubic = splines.evaluate(t)\n",
    "    mask = ~np.isnan(vector.numpy()).flatten()\n",
    "    t_clean = t.numpy()[mask]\n",
    "    vector_clean = vector.numpy()[mask].flatten()\n",
    "    pchip = PchipInterpolator(t_clean, vector_clean)\n",
    "    # add end point by cubic spline\n",
    "    arr = pchip(t)  # Get the array\n",
    "    arr[CT_selected_indices_shift[-1]:] = theta_vec_cubic[CT_selected_indices_shift[-1]:].reshape(-1)  # Modify the slice  \n",
    "\n",
    "    plt.scatter(CT_selected_indices_shift, angl, label='Original', color='red')\n",
    "    plt.plot(pchip(t)[:410], label='Pchip', color='orange')\n",
    "    plt.plot(theta_vec_cubic, label='Cubic', color='green')\n",
    "    plt.plot(arr, label='Final', color='blue')\n",
    "    plt.legend()\n",
    "    ct_data_or  = torch.tensor(post_data[:,:,idx_CT_shift:CT_sdf_cpr.shape[1]+idx_CT_shift]).permute(2, 0, 1).unsqueeze(0)\n",
    "    oct_data_or = torch.tensor(pre_data[:,:,idx_OCT_shift:OCT_sdf_cpr.shape[1]+idx_OCT_shift]).permute(2, 0, 1).unsqueeze(0)\n",
    "\n",
    "    ph_or = ridgit_register(ct_data_or[0], torch.tensor(np.array(arr).reshape(-1,1)))\n",
    "    ph = ridgit_register(CT_sdf_cpr[0], torch.tensor(np.array(arr).reshape(-1,1)))\n",
    "\n",
    "    ct_circl = []\n",
    "    for i in range(CT_sdf_cpr.shape[1]):\n",
    "        orientation,centroid = center_circle(ph.unsqueeze(0)[0,i,...].detach().numpy()>0)\n",
    "        ct_circl.append(centroid)\n",
    "\n",
    "    oct_circl= []\n",
    "    for i in range(OCT_sdf_cpr.shape[1]):\n",
    "        orientation,centroid = center_circle(OCT_sdf_cpr[0,i,...].detach().numpy()>0)\n",
    "        oct_circl.append(centroid)\n",
    "\n",
    "    # Convert centers to numpy arrays for easier processing\n",
    "    oct_circl = np.array([c for c in oct_circl if c[0] is not None and c[1] is not None])\n",
    "    ct_circl = np.array([c for c in ct_circl if c[0] is not None and c[1] is not None])\n",
    "   \n",
    "    # Ensure there are enough points to apply the filter\n",
    "    if len(oct_circl) > 31 and len(ct_circl) > 31:\n",
    "        # Smooth the center coordinates\n",
    "        oct_circl = np.copy(oct_circl)\n",
    "        ct_circl = np.copy(ct_circl)\n",
    "        \n",
    "        for dim in range(2):  # For both x and y dimensions\n",
    "            oct_circl[:, dim] = savgol_filter(oct_circl[:, dim], 32, 2)\n",
    "            oct_circl[:, dim] = savgol_filter(ct_circl[:, dim], 32, 2)\n",
    "   \n",
    "    ph_or_circle = rotation(ph_or.unsqueeze(0),oct_circl,ct_circl)\n",
    "    #ph_or_smooth_min = rotation(ph_or.unsqueeze(0),OCT_centers_smoothedmin,CT_centers_smoothedmin)\n",
    "    #ph_translation_smooth_min = rotation(ph.unsqueeze(0),OCT_centers_smoothedmin,CT_centers_smoothedmin)\n",
    "    ph_circle = rotation(ph.unsqueeze(0),oct_circl,ct_circl)\n",
    "\n",
    "\n",
    "\n",
    "    patient = patient_id\n",
    "    #d = torch.load('data_dict_bif_angl.pt')\n",
    "    d = {}\n",
    "    d[patient] = {}\n",
    "    ############################ PRE-FINAL ############################\n",
    "\n",
    "    d[patient]['bif_(PostTarget_StentMoving)'] = [organized_pairs,ang_big]\n",
    "    d[patient]['bif_(PostTarget_StentMoving)'][0]\n",
    "    # substract first tuple from all tuples in the list\n",
    "    l = [(x[0]-d[patient]['bif_(PostTarget_StentMoving)'][0][0][0], x[1]-d[patient]['bif_(PostTarget_StentMoving)'][0][0][1]) for x in d[patient]['bif_(PostTarget_StentMoving)'][0]]\n",
    "    fixed_image = oct_data_or.detach().numpy().squeeze().transpose(1, 2, 0)\n",
    "    moving_image = np.array(ph_or_circle).transpose(1, 2, 0)\n",
    "\n",
    "    bil = []\n",
    "    for i in range(len(l)-1):\n",
    "        \n",
    "        lengthf = fixed_image[:,:,l[i][1]:(l[i+1][1])].shape[-1]\n",
    "        lengthm = moving_image[:,:,l[i][0]:(l[i+1][0])].shape[-1]\n",
    "\n",
    "        frames = moving_image[:,:,l[i][0]:(l[i+1][0])]\n",
    "        print(lengthf-lengthm)\n",
    "        if (lengthf-lengthm)>0 and (l[i+1][1]-l[i][1])>5:\n",
    "            print('duplicate')\n",
    "            num_duplicates = lengthf - lengthm \n",
    "            sq = duplicate_frames(frames, num_duplicates=num_duplicates, exclusion_fraction=0.2)\n",
    "            bil.append(sq)\n",
    "        if (lengthf-lengthm)<0 and (l[i+1][1]-l[i][1])>5:\n",
    "            print('remove')\n",
    "            num_removals = lengthm - lengthf \n",
    "            sq = remove_frames(frames, num_removals=num_removals, exclusion_fraction=0.2)\n",
    "            bil.append(sq)\n",
    "\n",
    "        if (lengthf-lengthm)==0 or (l[i+1][1]-l[i][1])<=5:\n",
    "            print('normal')\n",
    "            bil.append(frames)\n",
    "    bil.append(moving_image[:,:,l[-1][0]:])\n",
    "    br = np.concatenate((bil),axis=2)\n",
    "    print(OCT_selected_indices_shift)\n",
    "    return CT_selected_indices_shift, OCT_selected_indices_shift, fixed_image, br, organized_pairs,ang_big,ct_data_or \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient = 'DK_AHU_00026'\n",
    "CT_selected_indices_shift,OCT_selected_indices_shift, fixed_image, br,organized_pairs,ang_big,ct_data_or = co_registration(patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images():\n",
    "    for index in OCT_selected_indices_shift:\n",
    "        fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "        \n",
    "        axs[0].imshow(fixed_image[...,index])\n",
    "        axs[0].set_title('Target(Pre)')\n",
    "\n",
    "        axs[1].imshow(br[:,:,index])\n",
    "        axs[1].set_title(f'{index} Resample random removal/duplicate')\n",
    "\n",
    "        axs[2].imshow(ct_data_or[0,index,...])\n",
    "        axs[2].set_title('Moving')\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "# Call the function to display images\n",
    "show_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'shape br{br.shape},shape fix{fixed_image.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ang_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(i):\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    axs[0].imshow(fixed_image[...,i])\n",
    "    axs[0].set_title('Target(Pre)')\n",
    "\n",
    "    axs[1].imshow(br[:,:,i])\n",
    "    axs[1].set_title('Resample random removel\\duplicate')\n",
    "    axs[2].imshow(ct_data_or[0,i,...])\n",
    "    axs[2].set_title('Moving')\n",
    "    plt.show()\n",
    "\n",
    "# Interactive slider\n",
    "frame_slider = IntSlider(min=0, max=fixed_image.shape[1]-1, step=1, value=0)\n",
    "interact(show_images, i=frame_slider)\n",
    "OCT_selected_indices_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ang_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = torch.load('data_dict_bif_angl_pre_post.pt')\n",
    "d[patient] = {}\n",
    "d[patient]['bif_(pre_t_post_m)'] = [organized_pairs,ang_big]\n",
    "torch.save(d, 'data_dict_bif_angl_pre_post.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brs = nib.Nifti1Image(br, np.eye(4))\n",
    "nib.save(brs, patient+'post.nii.gz')\n",
    "\n",
    "fixed_images = nib.Nifti1Image(fixed_image[:,:,:br.shape[-1]], np.eye(4))       \n",
    "nib.save(fixed_images, patient+'pre.nii.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fixed_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixed_image[:,:,:br.shape[-1]].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nib.load(patient+'post.nii.gz')\n",
    "plt.imshow(img.get_fdata()[:,:,0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = nib.load(patient+'pre.nii.gz')\n",
    "plt.imshow(img.get_fdata()[:,:,10], cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nameofmyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
